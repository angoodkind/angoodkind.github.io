---
layout: post
published: true
title: Boom! AI is the New Dynamite
# subtitle: but that doesn't matter...
tags: [AI]
image: /img/ai-dynamite-use.jpeg
output:
  html_document:
    keep_md: true
---

<img align="right" src="/img/ai-dynamite-use.jpeg" alt="A cartoon of a smiling robot playing with dynamite" style="width:30%">

I've been struggling to find an apt historical parallel to the recent explosion of AI for quite some time (maybe "explosion" should've been my clue). Then I read [this essay](https://adjacentpossible.substack.com/p/the-controlled-explosion?utm_source=post-email-title&publication_id=514230&post_id=141000309&utm_campaign=email-post-title&isFreemail=true&r=a3ya&utm_medium=email) from [Steven Johnson](https://substack.com/@adjacentpossible) this morning, and felt my head explode (again with the combustion analogies). Note: Johnson is a brilliant writer and I'd strongly encourage you to read the essay, or all of his books.

Part of his forthcoming book is about Alfred Nobel and his invention of dynamite. Nobel never foresaw the ultimately destructive or disruptive power of his invention, and in fact thought that its awesome power would lead to an inevitable truce between all world powers. But as Johnson explains:

> The invention of dynamite follows a pattern that has generally been true of scientific advances over the long term: science and technology puts ever-increasing power—power in the sense of energy, not politics—in the hands of smaller and smaller groups. Dynamite gave a solo anarchist the destructive power of a military platoon, which—for a while at least—threatened to level the playing field between the state, the industrial magnates, and the radicals who wanted to overthrow them.

If we follow this pattern across the last 150 years, I think it inevitably leads to AI: an incredible amount of power (both kinetic and political) lies in the hands of a single person with access to computing power. They don't even need to be resourceful and good with building objects, they just need the ability to type.

And now I'm asking myself, as the rubble of my mind settles, where does this leave us? I have my historical parallel (great!), but what can I take away from it? Here are my thoughts, but I'd love to hear yours:

### Sort Of Good

#### We have to listen to more people

As Johnson mentions, dynamite put the power of a military platoon in the hands of an individual. Suddenly, the world wasn't being shaped solely by kings and presidents, but by smaller forces as well. And so my most optimistic takeaway is that if everyone has a voice, then maybe it means that more people will have more rights. (Admittedly, this might be *overly* optimistic, but I don't want to be Debbie Downer this morning.)

#### Since we can't control it, we'll have to learn to detect it

We can't control dynamite. If someone can acquire the ingredients, and the instructions, they can still make dynamite on their own. But we have bomb detectors now. Similarly, maybe we need to get better about detecting when AI is being used. [Watermarking AI-generated images](https://deepmind.google/discover/blog/identifying-ai-generated-images-with-synthid/) is an active area of research, but it still [needs a lot of work](https://www.wired.com/story/artificial-intelligence-watermarking-issues/). 

### Not So Good

#### It's been superseded by more powerful explosives

We now have more powerful explosives, and nuclear weapons. So if Group A uses dynamite on Group B, Group B can retaliate with TNT. And so on and so forth. I can't conceive of what will supersede AI. I suppose you could say that Artificial General Intelligence is the next step above generative AI, but it's still AI.

#### Control access to ingredients

The ingredients for making dynamite are tightly controlled. I can't run to my neighborhood market and pick up nitroglycerin. The thought of a future where only certain people have access to computers is about as dystopian as it gets. But it doesn't seem outside the realm of possibility that a ruling class would use their power to do just this.

### Definitely Not Good

#### Dynamite didn't have the ability to decide when to detonate itself

Maybe AI really is a development without a historical parallel. Dynamite could go off accidentally, but it certainly wasn't deciding to detonate. Even "smart bombs" are only exploding when they satisfy the conditions set out by a programmer, e.g. they have hit the ground. But hypothetically an AI could make decisions that a human programmer never intended it to. And this brings us into a whole new realm, and possibly a future blog post.

Thoughts?

----

### Addendum

<!-- !["A cartoon of a robot playing with dynamite"](/img/ai-dynamite-evil.jpeg "Evil robot"){: width="50%";style="float : right"} -->

<img align="right" src="/img/ai-dynamite-evil.jpeg" alt="A cartoon of an evil robot playing with dynamite" style="width:30%">

The image at the top of this article was generated by DALLE. The initial image, to the right, was generated using the instructions `Generate a cartoon of a robot playing with dynamite.` I then had to correct it with `Make the robot's smile less evil.` But maybe this is a telltale sign of what AI thinks of itself, which does not bode well for us...

